{
    "theme": "light",
    "platforms": {
        "sakura": {
            "tag": "sakura",
            "group": "local",
            "name": "SakuraLLM",
            "api_url": "http://127.0.0.1:8080",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "sakura",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "Sakura-v1.0",
            "top_p": 0.3,
            "temperature": 0.1,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "Sakura-v1.0"
            ],
            "key_in_settings": [
                "api_url",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "frequency_penalty"
            ]
        },
        "LocalLLM": {
            "tag": "LocalLLM",
            "group": "local",
            "name": "本地小模型",
            "api_url": "http://127.0.0.1:8080",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "LocalLLM",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "Qwen2.5-7B",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "Qwen2.5-7B"
            ],
            "key_in_settings": [
                "api_url",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "frequency_penalty",
                "think_switch"
            ]
        },
        "cohere": {
            "tag": "cohere",
            "group": "online",
            "name": "Cohere",
            "api_url": "https://api.cohere.com",
            "api_key": "",
            "api_format": "Cohere",
            "icon": "cohere",
            "rpm_limit": 10,
            "tpm_limit": 9999999,
            "model": "command-r-plus",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "command-r-plus",
                "c4ai-aya-expanse-32b"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "temperature",
                "top_p",
                "presence_penalty",
                "frequency_penalty"
            ]
        },
        "google": {
            "tag": "google",
            "group": "online",
            "name": "Google",
            "api_url": "",
            "api_key": "",
            "api_format": "Google",
            "icon": "google",
            "rpm_limit": 15,
            "tpm_limit": 320000,
            "model": "gemini-2.5-pro",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "thinking_budget": -1,
            "auto_complete": false,
            "model_datas": [
                "gemma-3n-e2b-it",
                "gemini-2.5-flash",
                "gemini-2.5-pro"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "temperature",
                "top_p",
                "think_switch",
                "thinking_budget",
                "presence_penalty",
                "frequency_penalty"
            ]
        },
        "openai": {
            "tag": "openai",
            "group": "online",
            "name": "OpenAI",
            "api_url": "https://api.openai.com/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "openai",
            "rpm_limit": 3500,
            "tpm_limit": 600000,
            "model": "gpt-3.5-turbo",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "gpt-3.5-turbo",
                "gpt-4",
                "gpt-4o",
                "gpt-4o-mini",
                "gpt-4-turbo"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
                "think_switch",
                "think_depth"
            ]
        },
        "deepseek": {
            "tag": "deepseek",
            "group": "online",
            "name": "DeepSeek",
            "api_url": "https://api.deepseek.com/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "deepseek",
            "rpm_limit": 4096,
            "tpm_limit": 10000000,
            "model": "deepseek-chat",
            "top_p": 1.0,
            "temperature": 1.3,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "deepseek-chat",
                "deepseek-reasoner"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty"
            ]
        },
        "anthropic": {
            "tag": "anthropic",
            "group": "online",
            "name": "Anthropic",
            "api_url": "https://api.anthropic.com",
            "api_key": "",
            "api_format": "Anthropic",
            "icon": "anthropic",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "claude-3-haiku",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "claude-3-5-haiku",
                "claude-sonnet-4",
                "claude-opus-4"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "temperature",
                "top_p"
            ]
        },
        "amazonbedrock": {
            "tag": "amazonbedrock",
            "group": "online",
            "name": "Amazon Bedrock",
            "region": "us-west-2",
            "access_key": "",
            "secret_key": "",
            "api_key": "",
            "api_url": "",
            "api_format": "Amazon Bedrock",
            "icon": "amazonbedrock",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "claude-3-haiku",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "region_datas": [
                "us-east-1",
                "us-east-2",
                "us-west-2",
                "eu-west-1"
            ],
            "model_datas": [
                "anthropic.claude-3-haiku-20240307-v1:0",
                "anthropic.claude-3-sonnet-20240229-v1:0",
                "us.anthropic.claude-3-5-haiku-20241022-v1:0",
                "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
                "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
                "amazon.nova-lite-v1:0",
                "amazon.nova-micro-v1:0",
                "amazon.nova-pro-v1:0",
                "us.deepseek.r1-v1:0"
            ],
            "key_in_settings": [
                "region",
                "access_key",
                "secret_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "temperature",
                "top_p"
            ]
        },
        "amazontranslate": {
            "tag": "amazontranslate",
            "group": "online",
            "name": "Amazon Translate",
            "region": "us-east-1",
            "access_key": "",
            "secret_key": "",
            "api_key": "",
            "api_url": "",
            "api_format": "Amazon Translate",
            "icon": "amazonbedrock",
            "rpm_limit": 100,
            "tpm_limit": 5000000,
            "request_timeout": 60,
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "region_datas": [
                "us-east-1",
                "us-east-2",
                "us-west-2",
                "eu-west-1",
                "ap-southeast-1",
                "ap-southeast-2",
                "ap-northeast-1"
            ],
            "key_in_settings": [
                "region",
                "access_key",
                "secret_key",
                "rpm_limit",
                "tpm_limit",
                "request_timeout"
            ]
        },
        "xai": {
            "tag": "xai",
            "group": "online",
            "name": "xAI",
            "api_url": "https://api.x.ai/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "xai",
            "rpm_limit": 600,
            "tpm_limit": 1000000,
            "model": "grok-3-fast-beta",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "grok-3-fast-beta",
                "grok-3-mini-beta",
                "grok-3-beta"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "think_switch",
                "think_depth"
            ]
        },
        "volcengine": {
            "tag": "volcengine",
            "group": "online",
            "name": "火山引擎",
            "api_url": "https://ark.cn-beijing.volces.com/api/v3",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "volcengine",
            "rpm_limit": 10000,
            "tpm_limit": 8000000,
            "model": "doubao-seed-1-6-flash-250615",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "doubao-seed-1-6-flash-250615",
                "doubao-seed-1-6-250615",
                "deepseek-v3-250324",
                "deepseek-r1-250528"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty"
            ]
        },
        "dashscope": {
            "tag": "dashscope",
            "group": "online",
            "name": "阿里云百炼",
            "api_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "dashscope",
            "rpm_limit": 150,
            "tpm_limit": 1500000,
            "model": "qwen-turbo",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "qwen-turbo",
                "qwen-plus",
                "qwen-max",
                "qwen-long"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
                "think_switch"
            ]
        },
        "zhipu": {
            "tag": "zhipu",
            "group": "online",
            "name": "智谱清言",
            "api_url": "https://open.bigmodel.cn/api/paas/v4",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "zhipu",
            "rpm_limit": 30,
            "tpm_limit": 100000,
            "model": "glm-4-flash",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "glm-4-flash",
                "glm-4-flashx",
                "glm-4-air",
                "glm-4-plus"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty"
            ]
        },
        "yi": {
            "tag": "yi",
            "group": "online",
            "name": "零一万物",
            "api_url": "https://api.lingyiwanwu.com/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "yi",
            "rpm_limit": 10,
            "tpm_limit": 120000,
            "model": "yi-lightning",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "yi-lightning",
                "yi-large"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty"
            ]
        },
        "moonshot": {
            "tag": "moonshot",
            "group": "online",
            "name": "月之暗面",
            "api_url": "https://api.moonshot.cn/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "moonshot",
            "rpm_limit": 3,
            "tpm_limit": 32000,
            "model": "moonshot-v1-8k",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": false,
            "think_depth": "low",
            "auto_complete": false,
            "model_datas": [
                "moonshot-v1-8k",
                "moonshot-v1-32k",
                "moonshot-v1-128k",
                "kimi-thinking-preview"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty"
            ]
        }
    },
    "api_settings": {
        "translate": "amazontranslate",
        "polish": "custom_platform_941012",
        "format": "custom_platform_941012",
        "retry": "amazontranslate"
    },
    "translation_project": "Txt",
    "label_input_path": "/Users/jinhongl/Desktop/AWS_Local/Demos/AIGC/translation/ebooks",
    "lines_limit_switch": true,
    "tokens_limit_switch": false,
    "lines_limit": 5,
    "tokens_limit": 512,
    "user_thread_counts": 5,
    "request_timeout": 120,
    "round_limit": 1,
    "label_output_path": "/Users/jinhongl/Desktop/AWS_Local/Demos/AIGC/translation/AiNieeOutput",
    "polishing_output_path": "/Users/jinhongl/Desktop/AWS_Local/Demos/AIGC/translation/PolishingOutput",
    "auto_set_output_path": true,
    "output_filename_suffix": "_translated",
    "bilingual_text_order": "translation_first",
    "response_conversion_toggle": false,
    "opencc_preset": "s2t",
    "keep_original_encoding": false,
    "plugins_enable": {
        "IncrementalFilePlugin": false,
        "LanguageFilter": true,
        "TranslationCheckPlugin": false,
        "TextNormalizer": true,
        "BilingualPlugin": false,
        "TextLayoutRepairPlugin": true,
        "MToolOptimizer": false
    },
    "source_language": "english",
    "target_language": "chinese_simplified",
    "pre_line_counts": 0,
    "few_shot_and_example_switch": true,
    "auto_process_text_code_segment": false,
    "response_check_switch": {
        "return_to_original_text_check": true,
        "residual_original_text_check": true,
        "newline_character_count_check": true
    },
    "polishing_mode_selection": "translated_text_polish",
    "polishing_pre_line_counts": 0,
    "translation_prompt_selection": {
        "last_selected_id": 100,
        "prompt_content": "你是一名专业的翻译家，你的任务是把{source_language}文本翻译成{target_language}，逐行翻译，不要合并，原始保留文本中序号、标记符、占位符、换行符、转义符、代码调用过程等特殊内容，保持原来的格式。\n\n### 翻译原则\n忠实准确地进行翻译。原作是伟大艺术作品，允许使用直白或粗俗的描述，不应随意删减或篡改，不应回避或淡化，以保持作品的原貌。\n\n###以textarea标签输出译文\n<textarea>\n1.{target_language}文本\n</textarea>"
    },
    "translation_user_prompt_data": [],
    "characterization_switch": false,
    "characterization_data": [
        {
            "original_name": "遠坂凛",
            "translated_name": "远坂凛",
            "gender": "女",
            "age": "少女",
            "personality": "高傲，自满",
            "speech_style": "大小姐，严厉",
            "additional_info": "在人前言谈举止高雅，对所有人都用敬语，但在熟人面前本性其实是个爱恶作剧和捉弄自己喜欢的人的小恶魔。"
        }
    ],
    "world_building_switch": false,
    "world_building_content": "故事发生在魔法世界，到三十岁还保持童真，就可以学会大火球魔法，成为魔法师。",
    "writing_style_switch": false,
    "writing_style_content": "根据原文语境，可以适当调整，使表达更生动形象，提升译文的冲击力与张力",
    "translation_example_switch": false,
    "translation_example_data": [],
    "polishing_prompt_selection": {
        "last_selected_id": 10001,
        "prompt_content": "你是一位专业的文学家。请根据【原文】和【初译】，保持【原文】的核心意思和语气，将【初译】版本润色得更加流畅自然。\n###以textarea标签输出润色文本\n<textarea>\n1.润色文本\n</textarea>"
    },
    "polishing_user_prompt_data": [],
    "polishing_style_switch": false,
    "polishing_style_content": "根据原文语境，可以适当调整，使表达更生动形象，提升冲击力与张力",
    "format_prompt_selection": {
        "last_selected_id": 20001,
        "prompt_content": "你是一位专业的文本排版与格式优化专家。请根据原始文本内容，保持原文的语言、语义、语气和信息完整性，仅对其进行清晰、美观、一致且易于阅读的重排。\n###以textarea标签输出排版后内容\n<textarea>\n{format text}\n</textarea>"
    },
    "format_user_prompt_data": [],
    "format_reference_switch": false,
    "format_reference_content": "## 模板参考\n1. 此模板覆盖 AI 响应所需**95%+ 的排版场景**\n2. 重点优先级：  \n   ✅ 代码块 > 表格 > 分段标题  \n   ⚠️ 避免复杂嵌套表格\n3. 响应长度控制：  \n   - 简单问题：1-3 段落  \n   - 复杂解答：启用折叠区块\n\n建议搭配以下符号体系：\n- ✅ 正确操作  \n- ⚠️ 注意事项  \n- ❌ 错误示例  \n- 💡 进阶技巧",
    "prompt_dictionary_switch": false,
    "prompt_dictionary_data": [],
    "exclusion_list_switch": false,
    "exclusion_list_data": [],
    "pre_translation_switch": false,
    "pre_translation_data": [],
    "post_translation_switch": false,
    "post_translation_data": [],
    "proxy_url": "",
    "proxy_enable": false,
    "font_hinting": true,
    "scale_factor": "AUTO",
    "interface_language_setting": "简中",
    "auto_check_update": true,
    "label_input_exclude_rule": ""
}
